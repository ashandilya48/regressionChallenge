---
title: "Regression & Interpretability Challenge"
subtitle: "Don't Trust Linear Models â€“ The Perils of Non-Linearity"
format:
  html: default
execute:
  echo: true
  eval: true
---

# ğŸ—‘ï¸ Regression Challenge - Linear Model Interpretability

## Challenge Overview

**Your Mission:** Create a comprehensive Quarto document that demonstrates the dangers of trusting linear models when relationships are non-linear, analyzes the interpretability issues that arise, and presents compelling visual evidence of why we need to be skeptical of regression results. Then render the document to HTML and deploy it via GitHub Pages using the starter repository workflow.

## Problem Violating the Assumption of LinearityğŸ¯

> "We need to stop believing much of the empirical work we've been doing." - Christopher H. Achen

**The Core Problem:** When researchers need to 'control for' variables using linear regression, what happens when the relationships are non-linear? 

**What does "control for" mean?** Imagine you're studying whether social media causes anxiety. You know that stress is a major cause of anxiety, and you also suspect that social media use might cause anxiety. So you need to "control for" stress to see if social media has an independent effect on anxiety. You want to ask: "If two people have the same stress level, does the one who uses more social media have higher anxiety?"

Your challenge is to explore the simple example below and show how this happens:

$$
\begin{aligned}
A &\equiv \textrm{Anxiety Level measured by fMRI activity}\\
S &\equiv \textrm{Stress Level measured by cortisol level in blood}\\
T &\equiv \textrm{\# of minutes on social media in last 24 hours}
\end{aligned}
$$

Let's assume we **know** the relationship among these variables is as follows:

$$
Anxiety = Stress + 0.1 \times Time
$$

::: {.callout-important}
## ğŸ” Understanding the True Relationship: Implied Coefficients

**Critical Point:** Students often miss that this specific equation implies specific coefficient values in the generic multiple regression framework.

**The Generic Multiple Regression Equation:**
$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon
$$

**In Our Case:**
$$
Anxiety = \beta_0 + \beta_1 \times Stress + \beta_2 \times Time + \epsilon
$$

**The True Coefficients (what we "know"):**

- $\beta_0 = 0$ (intercept is zero)
- $\beta_1 = 1$ (coefficient on Stress is 1)  
- $\beta_2 = 0.1$ (coefficient on Time is 0.1)

**Why This Matters:** When we run regression analysis, we're trying to estimate these $\beta$ coefficients. If our regression gives us coefficients that are very different from these true values, we know our model is wrongâ€”even if it has good statistical fit!
:::

### The Data Generation Process

```{python}
#| echo: false
#| include: false
import pandas as pd

# Generate the "true" data with known relationships
observDF = pd.DataFrame({
    'Stress': [0, 0, 0, 1, 1, 1, 2, 2, 2, 8, 8, 8, 12, 12, 12],
    'StressSurvey': [0, 0, 0, 3, 3, 3, 6, 6, 6, 9, 9, 9, 12, 12, 12],
    'Time': [0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2.1, 2.2, 2.2, 2.2],
    'Anxiety': [0, 0.1, 0.1, 1.1, 1.1, 1.1, 2.2, 2.2, 2.2, 8.2, 8.2, 8.21, 12.22, 12.22, 12.22]
})
```

```{python}
#| label: tbl-observations
#| tbl-cap: "Observed data with known true relationships"
#| echo: true
observDF
```

### Questions to Answer for 75% Grade on Challenge

1. **Bivariate Regression Analysis with StressSurvey:** Run a bivariate regression of Anxiety on StressSurvey. What are the estimated coefficients? How do they compare to the true relationship?

:::{.callout-note}

## ğŸ“ˆ Bivariate Regression Analysis with StressSurvey

We performed a bivariate linear regression of **Anxiety** on **StressSurvey** using the provided dataset.

```{python}
#| label: bivariate model execution
#| echo: false

import pandas as pd
import statsmodels.api as sm

# Load the data
#observDF = pd.read_csv("data.csv")

# Define independent and dependent variables
X = observDF["StressSurvey"]
y = observDF["Anxiety"]

# Add constant for intercept
X = sm.add_constant(X)

# Fit the regression model
model = sm.OLS(y, X).fit()

# Print the summary
print(model.summary())

# Extract coefficients
intercept = model.params["const"]
slope = model.params["StressSurvey"]

print(f"Intercept: {intercept:.4f}")
print(f"Slope: {slope:.4f}")
# Print R-squared
print(f"R-squared: {model.rsquared:.4f}")
```

### ğŸ”¢ Estimated Model
The fitted regression equation is:

$$
\text{Anxiety} = -1.5240 + 1.0470 \cdot \text{StressSurvey}
$$

- **Intercept**: -1.5240  
- **Slope**: 1.0470  
- **RÂ²**: High, indicating strong linear association

### ğŸ§  Comparison to True Relationship
The true generative model is assumed to be:

$$
\text{Anxiety} = \text{Stress} + 0.1 \cdot \text{Time}
$$

- **StressSurvey** is not part of the true model; it's a proxy for Stress.
- The estimated slope (1.0470) captures correlation but not causation.
- The intercept deviates significantly due to omitted variable bias (Time not included).
- The model fit is statistically strong but **misspecified** relative to the true structure.

### âœ… Insight
While the regression on StressSurvey yields a strong fit, it does not reflect the true underlying relationship. Including both **Stress** and **Time** as predictors would yield a more accurate and interpretable model.

:::

2. **Visualization of Bivariate Relationship:** Create a scatter plot with the regression line showing the relationship between StressSurvey and Anxiety. Comment on the fit and any potential issues.

:::{.callout-note}

## ğŸ“Š Visualization Summary: StressSurvey vs Anxiety

The scatter plot illustrates the relationship between **StressSurvey** and **Anxiety**, with observed data points overlaid by a fitted regression line. The line follows the upward trend in the data, suggesting a strong linear association. Clusters at StressSurvey levels 3, 6, 9, and 12 show consistent increases in Anxiety, reinforcing the modelâ€™s predictive alignment.


```{python}
#| label: plotting regression line & R2
#| echo: false

import matplotlib.pyplot as plt
import seaborn as sns

# Extract predictions and residuals
observDF["Predicted_Anxiety"] = model.predict(X)
observDF["Residuals"] = observDF["Anxiety"] - observDF["Predicted_Anxiety"]

# Plot regression line over data points
plt.figure(figsize=(8, 5))
sns.scatterplot(x="StressSurvey", y="Anxiety", data=observDF, label="Observed")
sns.lineplot(x="StressSurvey", y="Predicted_Anxiety", data=observDF, color="red", label="Regression Line")
plt.title("Regression Line: Anxiety ~ StressSurvey")
plt.xlabel("StressSurvey")
plt.ylabel("Anxiety")
plt.legend()
plt.grid(True)
plt.show()

# Plot residuals
plt.figure(figsize=(8, 5))
sns.residplot(x="StressSurvey", y="Anxiety", data=observDF, lowess=True, color="purple")
plt.title("Residual Plot")
plt.xlabel("StressSurvey")
plt.ylabel("Residuals")
plt.grid(True)
plt.show()

```


## ğŸ“ˆ Model Fit

The bivariate regression yields the following equation:

$$
\text{Anxiety} = -1.5240 + 1.0470 \cdot \text{StressSurvey}
$$

- **RÂ² â‰ˆ 0.9011**, indicating that StressSurvey explains nearly all the variation in Anxiety.
- The regression line passes through the center of the data clusters, suggesting a statistically strong fit.

---

## âš ï¸ Potential Issues

Despite the high RÂ², the model is **misspecified** relative to the true generative process:

- The true relationship is:
  $$
  \text{Anxiety} = \text{Stress} + 0.1 \cdot \text{Time}
  $$
  StressSurvey is not a direct input to Anxietyâ€”it likely acts as a proxy for Stress.
- **Omitted Variable Bias**: Time and Stress are excluded, which distorts the intercept and inflates the slope.
- **Intercept Bias**: The estimated intercept (-1.5240) deviates significantly from the true modelâ€™s implied intercept (~0.01).
- **Collinearity Risk**: If StressSurvey is derived from Stress, the model may capture correlation without reflecting causation.


:::


3. **Bivariate Regression Analysis with Time:** Run a bivariate regression of Anxiety on Time. What are the estimated coefficients? How do they compare to the true relationship?

::: {.callout-note}

## ğŸ“ˆ Bivariate Regression Analysis with Time

We performed a bivariate linear regression of **Anxiety** on **Time** using the observed dataset.

### ğŸ”¢ Estimated Model

The fitted regression equation is:

$$
\text{Anxiety} = -3.6801 + 5.3406 \cdot \text{Time}
$$

- **Intercept**: -3.6801  
- **Slope**: 5.3406  

```{python}
#| echo: false

import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns

# Define independent and dependent variables
X = observDF["Time"]
y = observDF["Anxiety"]

# Add constant for intercept
X_const = sm.add_constant(X)

# Fit the regression model
model = sm.OLS(y, X_const).fit()

# Extract coefficients
intercept = model.params["const"]
slope = model.params["Time"]

# Print coefficients
print(f"Estimated Intercept: {intercept:.4f}")
print(f"Estimated Slope: {slope:.4f}")
# Print R-squared
print(f"R-squared: {model.rsquared:.4f}")

```

### ğŸ§  Comparison to True Relationship

The true generative model is:

$$
\text{Anxiety} = \text{Stress} + 0.1 \cdot \text{Time}
$$

- The estimated model **omits Stress**, a key predictor.
- As a result, the slope (5.3406) is **inflated**, absorbing the effect of both Stress and Time.
- The intercept is **biased downward**, reflecting the missing Stress contribution at Time = 0.


### âš ï¸ Interpretation

While the model shows a strong statistical fit, it is **misspecified**. Time alone cannot explain Anxiety accurately without accounting for Stress. This highlights the importance of including all relevant predictors when modeling real-world relationships.

:::


4. **Visualization of Bivariate Relationship:** Create a scatter plot with the regression line showing the relationship between Time and Anxiety. Comment on the fit and any potential issues.

::: {.callout-note}
## Visualization of Bivariate Relationship b/w Time and Anxiety

## Bivariate Regression: Anxiety vs Time

```{python}
#| echo: false

import matplotlib.pyplot as plt
import seaborn as sns

# Create predictions for plotting
observDF["Predicted_Anxiety"] = model.predict(X_const)

# Plot scatter and regression line
plt.figure(figsize=(8, 5))
sns.scatterplot(x="Time", y="Anxiety", data=observDF, label="Observed")
sns.lineplot(x="Time", y="Predicted_Anxiety", data=observDF, color="red", label="Regression Line")
plt.title("Regression of Anxiety on Time")
plt.xlabel("Time")
plt.ylabel("Anxiety")
plt.legend()
plt.grid(True)
plt.show()


```
### ğŸ“‰ Scatter Plot Insights
- The scatter plot shows a **clustered pattern** at lower Time values (0â€“2), with Anxiety values ranging from 0 to 2.2.
- However, **three extreme outliers** (Anxiety = 8.2 and 12.22 at Time â‰ˆ 2.0â€“2.2) **skew the regression line upward**, inflating the slope and reducing model reliability.

### âš ï¸ Potential Issues
- **Outliers**: The data points at Time â‰ˆ 2.0â€“2.2 with Anxiety > 8 are **inconsistent with the true model** (Anxiety = Stress + 0.1 Ã— Time). These likely represent data entry errors or a different regime.
- **Multicollinearity**: Since Anxiety is known to depend on both Stress and Time, omitting Stress from the model introduces **omitted variable bias**.
- **Non-linearity**: The true relationship is additive with Stress, not purely linear in Time.

:::


5. **Multiple Regression Analysis:** Run a multiple regression of Anxiety on both **StressSurvey** and Time. What are the estimated coefficients? How do they compare to the true relationship?

::: {.callout-note}
## Multiple Regression Analysis

### Estimated coefficients:
|Coefficient|Value|
|----|---:|
|Intercept      | 0.59 |
|StressSurvey   | 1.43 |
|Time           |-2.78 |

### ğŸ“ Comparison to True Relationship 

Specified the true relationship is:

  $$
  \text{Anxiety} = \text{Stress} + 0.1 \cdot \text{Time}
  $$

***This implies:***

- Stress has a 1.0 coefficient
- Time has a +0.1 coefficient
- No intercept

***However, in our regression:***

- StressSurvey (a proxy for Stress) is overestimated at **1.43**
- Time is strongly underestimated and even negative, at **â€“2.78**
- A **non-zero** intercept appears, which isnâ€™t part of the true relationship


:::


::: {.callout-tip}
## ğŸ¯ Remember the True Coefficients!

When analyzing your multiple regression results, compare them to the **true relationship** we established:

**True Coefficients:**

- Intercept ($\beta_0$) = 0
- Stress coefficient ($\beta_1$) = 1  
- Time coefficient ($\beta_2$) = 0.1

**Key Questions:**

- Are your estimated coefficients close to these true values?
- If not, what does this tell you about the reliability of your regression model?
- Even if your R-squared is high, are the coefficients telling the right story?
:::

### Questions to Answer for 85% Grade on Challenge

6. **Multiple Regression Analysis:** Run a multiple regression of Anxiety on both **Stress** and Time. What are the estimated coefficients? How do they compare to the true relationship?

:::{.callout-note}
## Multiple regression of Anxiety on both **Stress** and **Time**

### ğŸ“Š Estimated Regression Coefficients

- Intercept: â€“0.0003
- Stress coefficient: 1.0000
- Time coefficient: 0.1000

### âœ… Comparison to True Relationship

True relationship:

  $$
  \text{Anxiety} = \text{Stress} + 0.1 \cdot \text{Time}
  $$

### The estimated coefficients match this exactly:

- Stress: 1.0000 (true: 1.0)
- Time: 0.1000 (true: 0.1)
- Intercept: â‰ˆ 0 (negligible)

### ğŸ” Interpretation

- The regression **perfectly** recovers the **true** relationship.
- This confirms that the observed **Anxiety** values were generated using the formula provided, with **no added noise**.
- The **near-zero** intercept suggests **no** systematic bias.

:::


7. **Model Comparison:** Compare the R-squared values and coefficient interpretations between the two multiple regression models. Do both models show statistical significance in all of their coefficient estimates? What does this tell you about the real-world implications of multiple regression results?

::: {.callout-note}
## Model Comparison

### Coefficient Comparison

|Model|Intercept|StressSurvey|Stress|Time|R2|
|----|---:|---:|---:|---:|---:|
|StressSurvey|0.59|1.43|NaN|-2.78|0.94|
|Stress|~0|NaN|1.00|0.10|1.00|

### ğŸ“Š Statistical Significance of Coefficients

1. Model: Anxiety ~ StressSurvey + Time
  - StressSurvey: Statistically significant (p-value â‰ª 0.05)
  - Time: Not significant (p-value â‰« 0.05)
  - Intercept: Significant
2. Model: Anxiety ~ Stress + Time
  - Stress: Statistically significant (p-value â‰ª 0.05)
  - Time: Statistically significant (p-value â‰ª 0.05)
  - Intercept: Not significant (p-value â‰ˆ 1.0)

### ğŸ§  Real-World Implications

**âœ… Significance â‰  Importance**

- In the StressSurvey model, Time appears insignificant, even though we know from the true relationship that Time contributes meaningfully (0.1Â·Time).
- This shows that multicollinearity or poor proxy variables (like StressSurvey) can distort significance tests.

**ğŸ” Model Specification Matters**

- The Stress model correctly identifies both predictors as significant, aligning with the true data-generating process.
- This highlights the importance of using accurate, well-defined predictors. Poor proxies can lead to misleading inferences.

**âš ï¸ Donâ€™t Trust Significance Alone**

***Statistical significance is sensitive to:***

- Sample size
- Noise
- Collinearity
- Model misspecification
- A non-significant coefficient doesnâ€™t mean the variable is irrelevantâ€”it might be masked by other factors.

:::


### Questions to Answer for 95% Grade on Challenge

8. **Reflect on Real-World Implications:** For each of the two multiple regression models, assume their respective outputs/conclusions were published in academic journals and then subsequently picked up by the popular press.  What headline about time spent on social media and its effect on anxiety would you expect to see from a popular press outlet covering the first model? And what headline would you expect to see from a popular press outlet covering the second model?  Assuming confirmation bias is real, which model is a typical parent going to believe?  Which model will Facebook, Instagram, and TikTok executives prefer?

::: {.callout-note}
## Reflection on Real-World Implications

### ğŸ“° Popular Press Headlines Based on Each Model

**1. Model: Anxiety ~ StressSurvey + Time**

This model showed:

-	**StressSurvey:** significant positive effect
-	**Time:** negative and non-significant effect

**Likely headline:**

> ***Study Finds More Time on Social Media May Lower Anxietyâ€”But Stress Levels Still Matter***

**Narrative angle:**

-	Time spent online appears **protective** or **neutral**
-	StressSurvey (possibly linked to perceived stress or platform engagement) drives anxiety
-	Suggests social media isnâ€™t the villainâ€”itâ€™s how stressed you feel while using it

**2. Model: Anxiety ~ Stress + Time**

This model recovered the true relationship:

-	**Stress:** strong positive effect
- **Time:** modest positive effect

**Likely headline:**

> ***More Time on Social Media Linked to Higher Anxiety, Study Confirms***

**Narrative angle:**

-	Time spent online contributes directly to anxiety
-	Stress amplifies the effect
-	Reinforces public concerns about screen time and mental health

### ğŸ§  Confirmation Bias: Who Believes What?

**ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ Typical Parents**

-	**Will likely believe the second model**
-	It confirms their intuition: â€œToo much screen time is bad for my childâ€
-	Aligns with broader cultural narratives about tech and mental health

**ğŸ¢ Social Media Executives (Facebook, Instagram, TikTok)**

-	**Will prefer the first model**
-	It suggests time on their platforms isnâ€™t harmful
-	Shifts blame to user stress or external factors
-	Supports PR messaging: â€œWeâ€™re not the problemâ€”stress isâ€

:::

### Questions to Answer for 100% Grade on Challenge

9. **Avoiding Misleading Statistical Significance:** Reflect on this tip to avoid being misled by statistically significant results: splitting the sample into meaningful subsets ("statistical regimes"), and using graphical diagnostics for linearity rather than blind reliance on "canned" regressions. Apply this approach to multiple regression of Anxiety on both StressSurvey and Time by analyzing a smartly chosen subset of the data. What specific subset did you choose and why?  Did you get results that are both statistically significant and close to the true relationship?

::: {.callout-note}

> **Subset chosen:** StressSurvey between **0** and **6**. This regime yielded statistically significant results with coefficients that closely match the true relationship.

### ğŸ¯ Why This Subset?

I selected the subset where **StressSurvey is between 0 and 6**, which corresponds to the lower and mid-range stress levels. This regime includes:

- StressSurvey values: 0, 3, and 6
- Corresponding Stress values: 0, 1, and 2

This choice is strategic because:

- **StressSurvey is linearly related to Stress** in this range (StressSurvey â‰ˆ 3 Ã— Stress)
- The relationship between Anxiety and its predictors is likely more stable and linear
- It avoids the high-stress regime (StressSurvey = 9 or 12), where nonlinear effects or saturation may distort inference

### ğŸ“Š Regression Results (Subset: StressSurvey â‰¤ 6)

- **Intercept:** ~0.0000 (not significant)
- **StressSurvey coefficient:** 0.3333 (p â‰ˆ 3.09 Ã— 10â»â¹Â¹)
- **Time coefficient:** 0.1000 (p â‰ˆ 1.49 Ã— 10â»â¸â´)
- **R-squared:** 1.0000

### âœ… Comparison to True Relationship

***True relationship:***

  $$
  \text{Anxiety} = \text{Stress} + 0.1 \cdot \text{Time}
  $$

**Since StressSurvey = 3 Ã— Stress in this regime:**

- The estimated coefficient of **0.3333** for StressSurvey aligns perfectly with the true Stress coefficient of **1.0**
- The **Time coefficient** is exactly **0.1**
- **Perfect RÂ²** and extremely low p-values confirm a strong linear fit

### ğŸ§  Key Takeaways

- **Subsetting by regime** revealed the true relationship that was obscured in the full model
- **Blind reliance on full-sample regressions** can misleadâ€”especially when proxies like StressSurvey distort measurement

:::


> Remember: **Correlation is not causation, and regression coefficients can lie!** ğŸ“Š
